# import hashlib
# import sys

# from Config import yaml
import Config.json.jsondata as _json
import Config.json.jsonops as json
import Config.configops as config
import Utils.system.check_if_file_exist as system
import Utils.system.check_sys_time as systime

import Utils.logs as syslog
from Config.json.jsonops import json_log_entry
from Config import yaml_config_filepath
import hashlib

from Utils.uuid import generate_random_uuid
from Utils.system import get_nodes_name

# Defining dependencies for run_hash_computation function
__TARGETED_LOG_FILE = config.getServicesLogPaths()

# use getServicesName() from config to store a list of paths to files from CONFIG.YAML
__TARGETED_SERVICE_NAMES = config.getServicesName()

# run check on TARGETED_LOG_FILE to see if files exist within the system
__file_path_exist = system.check_if_file_exist(yaml_config_filepath)

#Defining the buff size used for file operations
BUFF_SIZE = 65536

def getFilesHash(logs_path: list):

    # Checking if logs+path passed into function is of type: list
    if isinstance(logs_path, list):

        # Creating an empty list to append hashes generated by this function later on

        list_of_hashes = []

        # Iterating through each log in logs_path
        for logs in logs_path:

             # Re-initalizing hash for use in the script
            hasher = hashlib.sha256()

            # opening up each log
            with open(logs, "rb") as f:

                while True:
                    
                    # Reading data according to BUFF_SIZE
                    data = f.read(BUFF_SIZE)

                    if not data:

                        break
                    
                    # data the hash stored in hasher Object
                    hasher.update(data)
                
                list_of_hashes.append(hasher.hexdigest())
            
        return list_of_hashes
    
    elif logs_path is None:

        syslog.logging.critical("No valid paths listed in YAML Config")

def getListOfHashes(files):

    getFilesHash(files)

def compare_hashes(uuid : str, uuid2: str):

    entry1 = json_log_entry(uuid=uuid)

    entry2 = json_log_entry(uuid=uuid2)

    if entry1['hashes_generated'] == entry2['hashes_generated']:

        print("this is the exact same file as before")

def run_hash_computation():

    config.readYamlConfig()
    # Checking if files listed in YAML Config exist within the system
    if __file_path_exist == True:

        # calling generate_random_uuid to generate a UUID for this hashing operation
        hashops_uuid = generate_random_uuid()
        # calculate and return hash of all the files present in YAML Config
        cal_hash = getFilesHash(__TARGETED_LOG_FILE)

        operations = _json.Jsonlog(hostname=get_nodes_name(),
                                   UUID=hashops_uuid,
                                   timestamp=systime.get_sys_utc_time(),
                                   targeted_paths=__TARGETED_LOG_FILE, 
                                   targeted_services=__TARGETED_SERVICE_NAMES, 
                                   hashes_generated=cal_hash)

        json.write_to_json(operations)

    # print to console - hashes were successfully calculated for the targeted services after hashes were calculated
    syslog.logging.info(f"Calculated hashes successfully for: {__TARGETED_SERVICE_NAMES}")